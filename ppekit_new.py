# -*- coding: utf-8 -*-
"""PPEKit_New.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11C5llUuANIkH-VBZiqXd0Kxwm0or6idK
"""

import gdown
file_id = '18ZpuKQoVn-Ntak9ujGRpErSoAi1JVuFX'
zip_path = '/content/PPEDetection.zip'
gdown.download(f'https://drive.google.com/uc?id={file_id}', zip_path, quiet=False)

!unzip PPEDetection.zip

!pip install ultralytics

!pip install gtts

import warnings
warnings.filterwarnings('ignore')

import os
import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random
import cv2
import yaml
from PIL import Image
from collections import deque
from ultralytics import YOLO
from IPython.display import Video

from gtts import gTTS
from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip

sns.set(rc={'axes.facecolor': '#ffe4de'}, style='darkgrid')

model = YOLO('yolov8n.pt')

dataset_path = '/content'

yaml_file_path = os.path.join(dataset_path, 'data.yaml')

with open(yaml_file_path, 'r') as file:
    yaml_content = yaml.load(file, Loader=yaml.FullLoader)
    print(yaml.dump(yaml_content, default_flow_style=False))

# Paths for ppd1 images
train_images_path_ppd1 = os.path.join(dataset_path, 'train', 'images')
test_images_path_ppd1 = os.path.join(dataset_path, 'test', 'images')
valid_images_path_ppd1 = os.path.join(dataset_path, 'valid', 'images')

# Initialize counters and sets for image sizes
num_train_images_ppd1 = 0
num_test_images_ppd1 = 0
num_valid_images_ppd1 = 0

train_image_sizes_ppd1 = set()
test_image_sizes_ppd1 = set()
valid_image_sizes_ppd1 = set()

# Process ppd1 training images
for filename in os.listdir(train_images_path_ppd1):
    if filename.endswith('.jpg'):
        num_train_images_ppd1 += 1
        image_path = os.path.join(train_images_path_ppd1, filename)
        with Image.open(image_path) as img:
            train_image_sizes_ppd1.add(img.size)

# Process ppd1 testing images
for filename in os.listdir(test_images_path_ppd1):
    if filename.endswith('.jpg'):
        num_test_images_ppd1 += 1
        image_path = os.path.join(test_images_path_ppd1, filename)
        with Image.open(image_path) as img:
            test_image_sizes_ppd1.add(img.size)

# Process ppd1 validation images
for filename in os.listdir(valid_images_path_ppd1):
    if filename.endswith('.jpg'):
        num_valid_images_ppd1 += 1
        image_path = os.path.join(valid_images_path_ppd1, filename)
        with Image.open(image_path) as img:
            valid_image_sizes_ppd1.add(img.size)

# Print results
print(f"Number of training images for ppd1: {num_train_images_ppd1}")
print(f"Number of testing images for ppd1: {num_test_images_ppd1}")
print(f"Number of validation images for ppd1: {num_valid_images_ppd1}")

if len(train_image_sizes_ppd1) == 1:
    print(f"All training images for ppd1 have the same size: {train_image_sizes_ppd1.pop()}")
else:
    print("Training images for ppd1 have varying sizes.")

if len(test_image_sizes_ppd1) == 1:
    print(f"All training images for ppd1 have the same size: {test_image_sizes_ppd1.pop()}")
else:
    print("Training images for ppd1 have varying sizes.")

if len(valid_image_sizes_ppd1) == 1:
    print(f"All validation images for ppd1 have the same size: {valid_image_sizes_ppd1.pop()}")
else:
    print("Validation images for ppd1 have varying sizes.")

image_files = [f for f in os.listdir(train_images_path_ppd1) if f.endswith('.jpg')]

random_images = random.sample(image_files, 15)

plt.figure(figsize=(20, 12))

for i, image_file in enumerate(random_images):
    image_path = os.path.join(train_images_path_ppd1, image_file)
    image = Image.open(image_path)
    plt.subplot(3, 5, i + 1)
    plt.imshow(image)
    plt.axis('off')

plt.suptitle('Random Selection of PPD1 Dataset Images', fontsize=24)

plt.tight_layout()
plt.show()

del image_files

results = model.train(
    data=yaml_file_path,
    epochs=150,
    imgsz=640,
    patience=30,
    batch=16,
    optimizer='auto',
    lr0=0.0001,
    lrf=0.01,
    dropout=0.25,
    device=0,
    seed=42
)

post_training_files_path = '/content/runs/detect/train'

files = os.listdir(post_training_files_path)
for file in files:
    print(file)

results_file_path = os.path.join(post_training_files_path, 'results.png')

image = cv2.imread(results_file_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(20, 8))
plt.imshow(image)
plt.title('Training and Validation Loss Trends', fontsize=24)
plt.axis('off')
plt.show()

def plot_learning_curve(df, train_loss_col, val_loss_col, title, ylim_range=[0,3]):
    plt.figure(figsize=(12, 5))
    sns.lineplot(data=df, x='epoch', y=train_loss_col, label='Train Loss', color='blue', linestyle='-', linewidth=2)
    sns.lineplot(data=df, x='epoch', y=val_loss_col, label='Validation Loss', color='#ed2f00', linestyle='--', linewidth=2)
    plt.title(title)
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.ylim(ylim_range)
    plt.legend()
    plt.show()

results_csv_path = os.path.join(post_training_files_path, 'results.csv')

df = pd.read_csv(results_csv_path)

df.columns = df.columns.str.strip()

plot_learning_curve(df, 'train/box_loss', 'val/box_loss', 'Bounding Box Loss Learning Curve')
plot_learning_curve(df, 'train/cls_loss', 'val/cls_loss', 'Classification Loss Learning Curve')
plot_learning_curve(df, 'train/dfl_loss', 'val/dfl_loss', 'Distribution Focal Loss Learning Curve')

def read_and_convert_image(file_path):
    image = cv2.imread(file_path)
    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

confusion_matrix_path = os.path.join(post_training_files_path, 'confusion_matrix.png')
confusion_matrix_normalized_path = os.path.join(post_training_files_path, 'confusion_matrix_normalized.png')

fig, axs = plt.subplots(1, 2, figsize=(20, 10))

cm_img = read_and_convert_image(confusion_matrix_path)
cm_norm_img = read_and_convert_image(confusion_matrix_normalized_path)

axs[0].imshow(cm_img)
axs[0].set_title('Confusion Matrix', fontsize=24)
axs[0].axis('off')

axs[1].imshow(cm_norm_img)
axs[1].set_title('Normalized Confusion Matrix', fontsize=24)
axs[1].axis('off')

plt.tight_layout()
plt.show()

best_model_path = os.path.join(post_training_files_path, 'weights/best.pt')

best_model = YOLO(best_model_path)

metrics = best_model.val(split='val')

metrics_df = pd.DataFrame.from_dict(metrics.results_dict, orient='index', columns=['Metric Value'])

metrics_df.round(3)

image_files = [file for file in os.listdir(valid_images_path_ppd1) if file.endswith('.jpg')]

num_images = len(image_files)
selected_images = [image_files[i] for i in range(0, num_images, num_images // 10)]

fig, axes = plt.subplots(3, 3, figsize=(20, 21))
fig.suptitle('Validation Set Inferences', fontsize=24)

for i, ax in enumerate(axes.flatten()):
    image_path = os.path.join(valid_images_path_ppd1, selected_images[i])
    results = best_model.predict(source=image_path, imgsz=640)
    annotated_image = results[0].plot()
    annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
    ax.imshow(annotated_image_rgb)
    ax.axis('off')

plt.tight_layout()
plt.show()

dataset_video_path = '/content/indianworkers.mp4'

video_path = 'sample_video.mp4'

shutil.copyfile(dataset_video_path, video_path)

predictions = best_model.predict(source=video_path, save=True)

input_path = "/content/runs/detect/predict/sample_video.avi"
output_path = "processed_sample_video.mp4"

clip = VideoFileClip(input_path)

clip.write_videofile(output_path, codec='libx264')

Video("processed_sample_video.mp4", embed=True, width=960)

